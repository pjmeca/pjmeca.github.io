[üè° Inicio](../../index.html)

# Tema 1: Arquitectura de un multiprocesador-en-un-chip (CMP)

## 

## √çndice

1. [Aspectos tecnol√≥gicos: Leyes de Moore y de Dennard](#Punto1)
2. [Clasificaci√≥n de Flynn. Principales figuras de m√©rito](#Punto2)
3. [Aspectos paralelos: Leyes de Amdahl y Gustafson](#Punto3)
4. [De sistemas empotrados a supercomputadores](#Punto4)

## 

## Aspectos tecnol√≥gicos: Leyes de Moore y de Dennard <a name="Punto1"></a>

### Arquitectura de computadores

La arquitectura de un computador est√° compuesta por:

- ISA (Instruction Set Architecture)
  
  - Conjunto de instrucciones que pueden ser ejecutadas por el procesador.
  
  - Ejemplos: x86, ARM, RISC-V

- Microarquitectura
  
  - C√≥mo se implementan las instrucciones del ISA

- Dise√±o tecnol√≥gico del sistema, es decir, el hardware

### Un resumen de la evoluci√≥n de las microarquitecturas

- Monociclo: Simple, pero eficiente

- Multiciclo

- Segmentaci√≥n
  
  - Permite la ejecuci√≥n **solapada** de varias instrucciones
  
  - Deben realizarse **detenciones** debido a los riesgos y **dependencias**.

- Explotando el ILP
  
  - Superescalares, Superpipelinning...
  
  - MultiThreading, Vectorizaci√≥n...

- **CMPs** (multiprocesadores en un chip)

- GPUs, DSPs, TPUs, XPUs (aceleradores)

- Supercomputadores

### Transistores y Cables

Denominamos **tama√±o caracter√≠stico** (*Feature size*)<a name="Tama√±oCaracteristico"></a> al tama√±o m√≠nimo del transistor en la dimensi√≥n *X* o *Y* (aunque habitualmente son la misma ya que suelen ser cuadrados). En el a√±o 1971 este tama√±o era de 10 micras, en el a√±o 2019 ya se hab√≠a reducido a tan solo **10 nan√≥metros**.

El tama√±o del transistor escala linealmente, es decir, el retardo en los cables no mejora con el tama√±o caracter√≠stico. La densidad de integraci√≥n escala cuadr√°ticamente.

**Densidad de Integraci√≥n** <a name="#NotaDensidadDeIntegraci√≥n"></a>: N√∫mero de componentes electr√≥nicos implantados por unidad de superficie en un circuito integrado, sea cual sea su tama√±o.

### Tendencias en tecnolog√≠a

- Circuitos Integrados (Ley de Moore)
  - Densidad de los transistores: +35% al a√±o.
  - Tama√±o del chip (dado): +10-20% al a√±o.
  - Mejora global: 40-55% al a√±o.
- Capacidad DRAM: +25-40% al a√±o (<span style="color:red">enlenteci√©ndose</span>)
  - 8 Hb (2014), 16 Gb (2017), 32 y 64 Gb (2019).
- Capacidad Flash: +50-60% al a√±o
  - Es de 8 a 10 veces m√°s barato el bit que en DRAM.
- Capacidad de los Discos Duros (HDDs): recientementa ha bajado al 5% el a√±o
  - No es posible mejorar la densidad, quiz√°s pasar de 7 a 9 discos.
  - Es de 8 a 10 vecesa m√°s barato el bit que en las memorias Flash.

### La ley de Moore (1965)

Se trata de una ley emp√≠rica formulada por el cofundador de Intel, Gordon E. Moore.

<img title="" src="http://dis.um.es/~lopezquesada/documentos/IES_1415/LMSGI/curso/css/css14/imagenes/gordonmoorebn.jpg" alt="Moore" width="142" data-align="center">

> La industria podr√° poner el doble de transistores en un chip cada 18-24 meses.

Esta *ley* se cumpli√≥ durante los a√±os 1955-2005 gracias a la ley de Dennard: 

> A medida que los transistores se hacen m√°s peque√±os, la densidad de potencia consumida por el circuito se mantiene constante.

Es importante destacar que en parte esta ley se *hizo cumplir*, ya que en realidad los transistores podr√≠an haber reducido su tama√±o con menos de 18 meses de diferencia, pero esto interesaba a Intel de cara a sus inversores.

### La ley de Dennard (1974)

La ley de Dennard (*Dennard scaling*), tambi√©n conocida como *MOSFET scaling*, fue propuesta en un art√≠culo de 1974 escrito por Robert H. Dennard junto a otros autores.

<img title="Robert H. Dennard" src="https://www.src.org/image/robert-dennard.png" alt="" data-align="center" width="164">

> Conforme los transistores van escalando, es decir, haci√©ndose m√°s pequelos, la densidad de potencia que consumen permanece constante.

Siendo la densidad de potencia:

$\frac{potencia}{√°rea}\frac W {cm^2}$

Ejemplo:

Si suponemos una reducci√≥n lineal en el tama√±o de los transistores en un factor de 2x, habr√° una reducci√≥n en el √°rea ocupada por cada transistor igual de 4x. Por lo tanto, podr√© poner 4x m√°s transistores.

La ley de Dennard predice que la potencia disipada por cada transistor disminuye tambi√©n en un factor de 4x (gracias a que disminuye el voltaje y la corriente). Es decir, el chip consume lo mismo mientras sea del mismo tama√±o.

### Consecuencias Dennard & Moore

Cuando el [tama√±o caracter√≠stico](#Tama√±oCaracteristico) del transistor se reduce por un factor de $x$, el n√∫mero de transistores en el chip aumenta por $x^2$, y el tama√±o dado del chip tambi√©n podr√≠a aumentar hasta un facor ~$x$. Por lo tanto, ¬°el rendimiento "bruto" del chip podr√≠a aumentar por ~$x^4$!

Es decir, pod√≠amos tener $x^3$ m√°s transistores, que se dedicaban a:

- Paralelismo: ILP (y √∫ltimamente vectorial)

- Localidad: cach√©s

Adem√°s, el *clock rate* (o frecuencia de funcionamiento) pod√≠a mejorar hasta ~$x$, porque los transistores pueden cambiar de estado m√°s r√°pido.

Gracias a estas mejoras, la mayor√≠a de los programas se ejecutaban $x^2$ veces m√°s r√°pido sin tener que cambiarlos.

Los procesadores (CPUs) doblaban su velocidad cada 18-24 meses si ten√≠amos una miniaturizaci√≥n de $\sqrt 2$.

### Problemas (*Walls*)

Al reducirse el tama√±o de los transistores (10 nm actualmente) y mantenerse constante el tama√±o del chip en torno a 2-4 cm$^2$, caben m√°s transistores y memoria cach√© en un procesador, sin embargo, aparecen los siguientes problemas:

- [Potencia consumida](#ProblemaPotencia)

- [Bajo paralelismo a nivel de instrucciones (ILP)](#ProblemaILP)

- [Memoria: latencia y ancho de banda](#ProblemaMemoria)

- [Fiabilidad](#ProblemaFiabilidad)

#### Potencia, energ√≠a y temperatura

La **energ√≠a** es el consumo (gasto) de potencia a lo largo del tiempo, se mide en **Julios** ($J = W¬∑s$) p kWh (kW gastados en 1 hora):

$Energ√≠a_{din√°mica}‚àù \frac {1}{2}\ CargaCapacitiva\ ¬∑\ V^2$

**Nota**: El s√≠mbolo ‚àù representa que algo es [proporcional](https://en.wiktionary.org/wiki/‚àù).

La **potencia** (el√©ctrica) debe ser tra√≠da y distribuida a lo largo del chip, de ah√≠ el n√∫mero de pines y las diversas capas (*layers*) que tiene el chip. Se mide en Vatios ($W = J/s$):

$Potencia_{din√°mica}‚àù \frac {1}{2}\ CargaCapacitiva\ ¬∑\ V^2\ ¬∑\ FrecuenciaCambio$

$Potencia_{est√°tica}‚àù \frac {1}{2}\ Corriente_{est√°tica}\ ¬∑\ V$

#### Problema de la potencia <a name="ProblemaPotencia"></a>

Componentes de la potencia:

$Potencia_{din√°mica}‚àù \frac {1}{2}\ CargaCapacitiva\ ¬∑\ V^2\ ¬∑\ FrecuenciaCambio$

$Potencia_{est√°tica}‚àù \frac {1}{2}\ Corriente_{est√°tica}\ ¬∑\ V=\frac {1}{2}\ Corriente_{fuga}\ ¬∑\ NTransistores\ ¬∑\ V$

Inicialmente, solo se ten√≠a en cuenta la **Potencia Din√°mica**, ya que la componente **Est√°tica** era casi despreciable.

Al no poder bajar el voltaje mucho m√°s de ‚âà0.5V, la densidad de potencia empez√≥ a aumentar (se dej√≥ de cumplir la ley de Dennard):

- La $P_{din√°mica}$ aumenta porque se sigue aumentando la frecuencia.

- La $P_{est√°tica}$ aumenta porque el n√∫mero de transistores sigue creciendo.

- En la actualidad, la potencia est√°tica puede estar en torno al 25-50% de la potencia total.

#### Potencia, energ√≠a y temperatura

La potencia y la temperatura est√°n directamente relacionadas:

- El procesador disipa potencia que se emite en forma de calor cada segundo. Esta potencia incrementa la temperatura del procesador.

- Hay que evitar que la temperatura se incremente demasiado disipando la energ√≠a emitida.

La **potencia de dise√±o t√©rmico** o TDP (*thermal design power*) se refiere a la potencia m√°xima disipada por el procesador suponiendo un uso sostenido (a m√°ximo rendimiento). Se utiliza como objetivo para la fuente de alimentaci√≥n y el sistema de refrigeraci√≥n.

#### ¬øC√≥mo reducir la potencia?

T√©cnicas habituales para reducir la potencia disipada:

- Reducir la frecuencia del reloj din√°micamente para limitar el consumo de energ√≠a.

- Reducir el voltaje din√°micamente cuando se reduce la frecuencia.

- Haciendo un apagado selectivo de zonas del procesador (p.ej: n√∫cleos).

- Situando en estados de bajo consumo de energ√≠a las memorias, los discos duros, etc.

#### El problema de la densidad de potencia

La potencia se disipa en forma de calor. La **densidad de potencia** ($W/cm^2$) es proporcional a la temperatura y determina la existencia de puntos calientes.

La CPU Intel 80286 disipaba unos 2 W, mientras que el actual Intel Core i7 a 3.3 GHz disipa unos 130 W.

<img title="" src="assets/aumento_densidad_potencia.png" alt="" data-align="center" width="642">

#### Rendimiento por potencia disipada

Otra m√©trica de inter√©s es el rendimiento por vatio disipado (*FLOPs/watt*).

El objetivo es lograr tener 1 ExaFlop con un consumo de 20 MWatts, lo que equivale a unos 50 GFLOPs/Watt. Una central nuclear proporciona entre 50 y 1000 MWatts, una central hidroel√©ctrica entre 500 y 20000 MWatts.

En su momento, el [UNIVAC I](https://es.wikipedia.org/wiki/UNIVAC_I) ten√≠a un consumo de 0.0015 FLOPs/Watt; en la actualidad:

- Kepler K80 (GPU): 9.8 GFLOPs/Watt

- Pascal chips P100 (GPU): 17.6 GFLOPs/Watt

- Knights Landing (CPU): 5.8 GFLOPs/Watt

- Xeon (CPU): menos de 5 GFLOPs/Watt

#### Eficiencia energ√©tica

La **energ√≠a** es la potencia consumida durante un tiempo determinado ($1\ J = 1\ W¬∑s$). Estando relacionadas, la m√©trica correcta para comparar procesadores es la de la energ√≠a (**eficiencia energ√©tica**). En concreto, el consumo de energ√≠a est√° relacionado con la realizaci√≥n de una determinada tarea en un tiempo determinado con un procesador determinado.

Por ejemplo: un procesador A podr√≠a tener un 20% m√°s de potencia disipada (watts) que el procesador B, pero si A ejecuta la tarea en un 70% del tiempo de B, el consumo de energ√≠a ser√°: $1,2 ¬∑ 0,7 = 0,84$ lo que representa un 16% de mejora energ√©tica para el procesador A.

#### Problema del calor (temperatura)

Las soluciones de *cooling* para altas frecuencias son o caras o poco pr√°cticas.

<img title="" src="assets/cooling.png" alt="" width="585" data-align="center">

#### El problema de aumentar el [ILP](https://en.wikipedia.org/wiki/Instruction-level_parallelism) <a name="ProblemaILP"></a>

El **tiempo de ejecuci√≥n** se define como:

$TiempoEjecuci√≥n=NI¬∑CPI¬∑\frac {1}{FrecuenciaReloj}$

Para disminuir el CPI podemos:

- Aumentar el bus de datos

- Hacer segmentaci√≥n (pero a partir de las 10 etapas aparecen muchos conflictos)

- Replicar cauce, lo que da lugar a una **ejecuci√≥n superescalar** (ejecutar m√°s de una instrucci√≥n por ciclo de reloj):
  
  - Se produce una [ejecuci√≥n fuera de orden (OoO)](https://es.wikipedia.org/wiki/Ejecuci√≥n_fuera_de_orden) y especulativa (predicci√≥n de saltos)
  
  - Hay que ser muy eficiente para resolver los frecuentes riesgos de datos y de control
  
  - Se utiliza mucho hardware, lo que provoca que se consuma mucha energ√≠a

#### El problema de la memoria <a name="ProblemaMemoria"></a>

La mejora de las CPUs es m√°s r√°pida que la mejora en el tiempo de acceso a la memoria RAM, por lo que cada vez las instrucciones pierden m√°s ciclos esperando a la memoria (latencia).

La ejecuci√≥n fuera de orden (OoO) solo puede mitigar parcialmente este problema. La mejora en el ancho de banda de memoria (n√∫mero de canales entre la CPU y la memoria) tampoco puede solucionar este problema.

#### El problema de la fiabilidad <a name="ProblemaFiabilidad"></a>

Es necesario un sistema de **tolerancia a fallos**, ya que, al ser los componentes cada vez m√°s peque√±os, son m√°s sensibles a las part√≠culas cargadas en el ambiente (pudi√©ndose cambiar 0 por 1 y viceversa), dando lugar a fallos. Cada vez es m√°s complicado que no falle una parte del circuito debido a la miniaturizaci√≥n.

En la actualidad, es com√∫n tener memorias y cach√©s con soluciones ECC (*Error Correction Code*). Pero por otro lado, cada vez es m√°s complicado comprobar un nuevo dise√±o para la (micro)arquitectura de un procesador.

M√©tricas:

- Tiempo medio hasta un fallo ($MTTF$)

- Tiempo medio para reparaciones ($MTTR$)

- Tiempo medio entre fallos ($MTBF$) = $MTTF + MTTR$

- Disponibilidad = $\frac {MTTF}{MTBF}$

#### Otros problemas de dise√±o monol√≠tico

Adicionalmente, el procesador presenta los siguientes problemas importantes:

- ***Clock skew* (sesgo de reloj)**: Un procesador es un circuito que funciona s√≠ncronamente. Los transistores reciben y alteran la se√±al de reloj, por lo que, al haber muchos transistores, puede haber modificaciones perceptibles en la se√±al de reloj.

- **Problemas el√©ctricos**: impedancia y capacitancia.

Esto da lugar al fen√≥meno conocido como [***Dark silikon***](https://en.wikipedia.org/wiki/Dark_silicon): no podremos utilizar una parte del procesador como consecuencia a estos problemas.

### Soluci√≥n: CMPs (*Chips Multiprocessors*)

- **Potencia**: Con n√∫cleos m√°s peque√±os se puede reducir la frecuencia y el voltaje para conseguir un mismo rendimiento, por consiguiente, varios n√∫cleos pueden alcanzar m√°s rendimiento/watt.

- **ILP**: El CMP tiene m√°s transistores √∫tiles que el dise√±o de un √∫nico procesador, lo que permite obtener un mejor rendimiento.

- **Memoria**: Se usan nodos NUMA, con localidad y menor latencia. Adem√°s, cada n√∫cleo usa su cach√© privada (L1 y L2, habitualmente).

- **Fiabilidad**: Tambi√©n mejoran la fiabilidad del chip por tener redundancia entre los n√∫cleos, y usar un mismo dise√±o para los diferentes n√∫cleos.

<img src="assets/ejemplo_cmp.png" title="" alt="" data-align="center">

<span style="color:green">Ventajas:</span>

- [x] En los CMP, cada n√∫cleo cuenta con su propio reloj, as√≠ que **desaparece** el sesgo de reloj y se **mitigan** los problemas el√©ctricos.

- [x] Es m√°s f√°cil verificar y validar el funcionamiento de varios chips simples que el de uno muy complejo (*time-to-market*).

- [x] **Redundancia y tolerancia a fallos**: Al tener los CMPs varios n√∫cleos, podemos dedicar uno o varios de ellos a comprobar lo que hacen los otros (redundancia).

Por tanto, se consigue un mayor rendimiento con menos consumo energ√©tico y teniendo que disipar menos calor.

### CMPs: explotando el paralelismo

A varios niveles:

- ILP, especulaci√≥n y r√©plica de cauces.

- Vecotres: Una instrucci√≥n sobre m√∫ltiples datos.

- N√∫cleos/hilos: M√∫ltiples instrucciones sobre m√∫ltiples datos.

<img title="" src="assets/ejemplo_cmps-paralelismo.png" alt="" data-align="center" width="595">

### La ley de Moore reinterpretada

- El n√∫mero de n√∫cleos por chip se puede doblar cada 2 a√±os.

- La frecuencia de reloj ya no se va a incrementar (de hecho, posiblemente se decremente).

- Es necesario manejar el paralelismo:
  
  - Dentro del n√∫cleo (*intra-core*): ILP y **unidades vectoriales**.
  
  - Entre los diversos n√∫cleos (*inter-core*): **M√∫ltiples n√∫cleos** en el procesador.

Actualmente necesitamos manejar procesadores con miles y millones de hilos de forma concurrente.

### Evoluci√≥n de los microprocesadores

<img title="" src="assets/40y_microprocesadores.png" alt="" data-align="center" width="608">

### Rendimiento de un √∫nico procesador

<img title="" src="assets/rendimiento_procesador.png" alt="" data-align="center" width="606">

## Clasificaci√≥n de Flynn. Principales figuras de m√©rito <a name="Punto2"></a>

### Clasificaci√≥n de arquitecturas

Taxonom√≠a de Michael J. Flynn (1972):

- **SISD**, *Single Instruction Single Data*
  
  - Sistemas monoprocesador basados en microprocesadores monocore como PCs antiguos (no CMPs).

- **SIMD**, *Single Instruction Multiple Data*
  
  - Procesadores vectoriales, GPUs.

- **MISD**, *Multiple Instruction SIngle Data*
  
  - Ninguna m√°quina comercial existente.

- **MIMD**, *Multiple Instruction Multiple Data*
  
  - Arquitectura adoptada por los computadores de hoy en d√≠a.
  
  - Procesadores multin√∫cleo, clusters, servidores, supercomputadores, etc.

### MIMD: Memoria compartida o distribuida

En la **memoria distribuida** cada procesador tiene su propia memoria local. Para comunicar datos se necesita usar expl√≠citamente instrucciones de paso de mensajes (por ejemplo, un [cl√∫ster](http://www.revista.unam.mx/vol.4/num2/art3/cluster.htm)).

En la **memoria compartida** hay un √∫nico espacio de direcciones al que todos los procesadores tienen acceso. La comunicaci√≥n de datos se realiza a trav√©s de operaciones t√≠picas de lectura/escritura de datos (por ejemplo, la arquitectura multin√∫cleo). Se accede a la memoria:

- Bus, Crossbar

- Red directa (por ejemplo, una malla)

> Ver v√≠deo

### Niveles de paralelismo expl√≠cito

<img title="" src="assets/niveles_paralelismo_explicito.png" alt="" width="614" data-align="center">

### Paralelismo

Clases de paralelismo en aplicaciones:

- Paralelismo de datos (DLP)

- Paralelismo de tareas (TLP)

Clases de paralelismo en arquitectura:

- Paralelismo de instrucciones (ILP, impl√≠cito o expl√≠cito)

- Arquitecturas vectoriales/Unidades de Procesamiento Gr√°ficos (GPUs)

- Paralelismo de hilos (CMPs, varios hilos por n√∫cleo, varios chips...)

### Principales figuras de m√©rito

- M√©tricas t√≠picas de rendimiento:
  
  - Tiempo de ejecuci√≥n
  
  - Productividad (*throughput*)

- Tiempo de ejecuci√≥n:
  
  - Tiempo de reloj de pared: incluye todos los *overheads* del sistema.
  
  - Tiempo de CPU (solo tiempo de c√°lculo)

- Aceleraci√≥n de X con respecto a Y:
  
  - $\frac {Tiempo_{ejecucion}Y}{Tiempo_{ejecucion}X}$

- Benchmarks:
  
  - Kernels (por ejemplo, la multiplicaci√≥n de matrices)
  
  - Programas de juguete (por ejemplo, sorting)
  
  - Benchmarks sint√©ticos (por ejemplo, Dhrystone)
  
  - Benchmarks suites (por ejemplo, SPEC06fp, TPC-C)

- Ecuaci√≥n del rendimiento del procesador:
  
   $CPU\ time = CPU\ clock\ cycles\ for\ a\ program\ ¬∑\ Clock\ cycle\ time$

¬†¬†¬†¬†¬†¬†¬†¬†$CPU\ time=\frac {CPU\ clock\ cycles\ for\ a\ program}{Clock\ rate}$

¬†¬†¬†¬†¬†¬†¬†¬†$CPI=\frac {CPU\ clock\ cycles\ for\ a\ program}{Instruction\ count}$

$CPU\ time = Instruction\ count\ ¬∑\ Cycles\ per\ instruction\ ¬∑\ Clock\ cycle\ time$

¬†¬†¬†¬†¬†¬†¬†¬†$CPU\ time=\frac {Instructions}{Program}¬∑\frac {Clock\ cycles}{Instruction}¬∑\frac {Seconds}{Clock\ cycle}=\frac {Seconds}{Program}$

- Instrucciones diferentes tienen diferentes CPIs

¬†¬†¬†¬†¬†¬†¬†¬†$CPU\ clock\ cycles=\sum_{i=1}^{n}IC_i\ ¬∑\ CPI_i$

¬†¬†¬†¬†¬†¬†¬†¬†$CPU\ time=(\sum_{i=1}^{n}IC_i\ ¬∑\ CPI_i)\ ¬∑\ Clock\ cycle\ time$

- Ancho de banda (a veces productividad)
  
  - Es el trabajo total realizado en un tiempo determinado.
  
  - Hay una mejora de entre el 32000 y el 40000 para los procesadores.
  
  - Hay una mejora de entre el 300 y el 1200 para la memoria y HDs.

- Latencia o tiempo de respuesta
  
  - Es el tiempo entre el comienzo y el fin de un evento.
  
  - Una mejora de entre el 50 y el 90 para procesadores.
  
  - Una mejora de entre el 6 y el 8 de mejora para memoria y HDs.

- Algunos valores que nos interesa conocer:
  
  - El rendimiento pico (*peak performance*) hace referencia, normalmente, de forma exclusiva a las operaciones en coma flotante.
  
  - MFLOPS (*Mega Floating point Operations Per Second*): millones de instrucciones en coma flotante ejecutadas por segundo.
  
  - TDP (*Thermal Design Power*): potencia m√°xima que puede llegar a disipar.
  
  - Frecuencia

- Tama√±os comunes:

<img title="" src="assets/medidas.png" alt="" data-align="center" width="600">

- A modo de referencia, el [ordenador m√°s r√°pido del mundo](http://www.top500.org/) tiene alrededor de 442 PFLOPS, 7.63M de cores y un consumo de 29.899 MW.

- Otros aspectos relevantes tambi√©n:
  
  - Frecuencia del reloj
  
  - N√∫mero de transistores
  
  - Tama√±o de la cach√© (y niveles)
  
  - Cantidad de memoria direccionable
  
  - Ancho de banda del bus a memoria
  
  - N√∫mero de n√∫cleos/hilos por chip
  
  - Tama√±o de la litograf√≠a
  
  - Tama√±o de los operandos

### Modelo de rendimiento *Roofline*
